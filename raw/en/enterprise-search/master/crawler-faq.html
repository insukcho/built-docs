<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Web crawler FAQ | Elastic Enterprise Search Documentation [master] | Elastic</title>
<link rel="home" href="index.html" title="Elastic Enterprise Search Documentation [master]"/>
<link rel="up" href="crawler.html" title="Web crawler"/>
<link rel="prev" href="crawler-scale-up.html" title="Scaling up: managing crawls in production (AKA advanced crawler configuration)"/>
<link rel="next" href="crawler-rules.html" title="Crawl rules"/>
<meta name="DC.type" content="Learn/Docs/Enterprise Search/Guide/master"/>
<meta name="DC.subject" content="Enterprise Search"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elastic Enterprise Search Documentation [master]</a></span>
»
<span class="breadcrumb-link"><a href="crawler.html">Web crawler</a></span>
»
<span class="breadcrumb-node">Web crawler FAQ</span>
</div>
<div class="navheader">
<span class="prev">
<a href="crawler-scale-up.html">« Scaling up: managing crawls in production (AKA advanced crawler configuration)</a>
</span>
<span class="next">
<a href="crawler-rules.html">Crawl rules »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="crawler-faq"></a>Web crawler FAQ<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-faq.asciidoc">edit</a></h2>
</div></div></div>
<p>View frequently asked questions about the Enterprise Search web crawler:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="crawler-faq.html#crawler-faq-what-functionality-is-supported" title="What functionality is supported?">What functionality is supported?</a>
</li>
<li class="listitem">
<a class="xref" href="crawler-faq.html#crawler-faq-what-functionality-is-not-supported" title="What functionality is not supported?">What functionality is not supported?</a>
</li>
<li class="listitem">
<a class="xref" href="crawler-faq.html#crawler-faq-crawler-comparison" title="Appendix: Compare Crawler2 and Crawler 1">Appendix: Compare Crawler2 with Crawler1</a>
</li>
</ul>
</div>
<p>See <a class="xref" href="crawler-reference.html" title="Crawler2 reference">Crawler2 reference</a> for detailed technical information about the web crawler.</p>
<h4><a id="crawler-faq-what-functionality-is-supported"></a>What functionality is supported?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-faq.asciidoc">edit</a></h4>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p><span class="strong strong"><strong>Crawling HTTP/HTTPS websites</strong></span></p>
<p>Includes support for both publicly-accessible and private/intranet web sites.
Self-signed SSL certificates and custom Certificate Authorities are supported.</p>
</li>
<li class="listitem">
<span class="strong strong"><strong>Support for crawling multiple domains per-Engine</strong></span>
</li>
<li class="listitem">
<span class="strong strong"><strong>Robots meta tag support</strong></span>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Robots "nofollow" support</strong></span></p>
<p>Includes robots meta tags set to "nofollow" and links with rel="nofollow" attributes.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Robots.txt support</strong></span></p>
<p>The web crawler honors directives within robots.txt files.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Sitemap support</strong></span></p>
<p>The web crawler honors XML sitemaps, and fetches sitemaps identified within robots.txt files.
Additional sitemaps can also be managed on the domain through the domain dashboard.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Configurable content extraction</strong></span></p>
<p>The web crawler will extract a predefined, set of fields (url, body content, etc) from each page it visits.
In addition to this, the crawler also supports extracting dynamic fields from meta tags.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>"Entry points"</strong></span></p>
<p>Entry points allow customers to specify where the web crawler begins crawling each domain.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>"Crawl rules"</strong></span></p>
<p>Crawl rules allow customers to control whether each URL the web crawler encounters will be visited and indexed.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Logging of each crawl</strong></span></p>
<p>Logs are representative of an entire crawl, which encompasses all domains in an engine.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Automatic crawling</strong></span></p>
<p>Configure the cadence for new crawls to start automatically if there isn&#8217;t an active crawl.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>User interfaces and APIs for managing domains, entry points, and crawl rules</strong></span></p>
<p>Crawler configuration can be managed via App Search dashboard UIs or via a set of public APIs provided by the product.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Crawl persistence</strong></span></p>
<p>Crawler uses Elasticsearch to maintain its state during an active crawl, allowing crawls to be migrated between instances in case of an instance failure or a restart of an Enterprise Search instance running a crawl.
Each unique URL is only visited once thanks to the Seen URLs list persisted in Elasticsearch.
Crawl-specific indexes are automatically cleaned up after a crawl is finished.</p>
</li>
<li class="listitem">
<p><span class="strong strong"><strong>Crawling websites behind authentication</strong></span></p>
<p>The web crawler can crawl content protected by HTTP authentication or content sitting behind an HTTP proxy (with or without authentication).
See the following references:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
web-crawler-reference-http-authentication
</li>
<li class="listitem">
web-crawler-reference-http-proxy
</li>
</ul>
</div>
</li>
</ul>
</div>
<h4><a id="crawler-faq-what-functionality-is-not-supported"></a>What functionality is not supported?<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-faq.asciidoc">edit</a></h4>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<p><span class="strong strong"><strong>Single-page app (SPA) support</strong></span></p>
<p>The crawler cannot currently crawl pages that are pure JavaScript single-page apps.
We recommend looking at <a href="https://developers.google.com/search/docs/advanced/javascript/dynamic-rendering" class="ulink" target="_top">dynamic rendering</a> to help your crawler properly index your JavaScript websites.</p>
</li>
</ul>
</div>
<h4><a id="crawler-faq-crawler-comparison"></a>Appendix: Compare Crawler2 and Crawler 1<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-faq.asciidoc">edit</a></h4>
<p><em>This table outlines the differences between Crawler2 and Crawler1 with a simple table.</em></p>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
</colgroup>
<tbody>
<tr>
<td align="left" valign="top"><p></p></td>
<td align="left" valign="top"><p><span class="strong strong"><strong>Crawler1</strong></span></p></td>
<td align="left" valign="top"><p><span class="strong strong"><strong>Crawler2</strong></span></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><span class="strong strong"><strong>Interface</strong></span></p></td>
<td align="left" valign="top"><p>GUI / API</p></td>
<td align="left" valign="top"><p>GUI-only in <span class="strong strong"><strong>8.4.0</strong></span></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><span class="strong strong"><strong>Binary content extraction</strong></span></p></td>
<td align="left" valign="top"><p>Yes</p></td>
<td align="left" valign="top"><p>Not in <span class="strong strong"><strong>8.4.0</strong></span></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><span class="strong strong"><strong>Search</strong></span></p></td>
<td align="left" valign="top"><p>App Search</p></td>
<td align="left" valign="top"><p><a href="/guide/en/elasticsearch/reference/8.3/search-your-data.html#run-an-es-search" class="ulink" target="_blank" rel="noopener">Elasticsearch</a>
/ App search using
<a href="/guide/en/app-search/current/elasticsearch-search-guide.html" class="ulink" target="_blank" rel="noopener">BYOEI</a></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><span class="strong strong"><strong>{Feature}</strong></span></p></td>
<td align="left" valign="top"><p>-</p></td>
<td align="left" valign="top"><p>-</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><span class="strong strong"><strong>{Feature}</strong></span></p></td>
<td align="left" valign="top"><p>-</p></td>
<td align="left" valign="top"><p>-</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><span class="strong strong"><strong>{Feature}</strong></span></p></td>
<td align="left" valign="top"><p>-</p></td>
<td align="left" valign="top"><p>-</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="navfooter">
<span class="prev">
<a href="crawler-scale-up.html">« Scaling up: managing crawls in production (AKA advanced crawler configuration)</a>
</span>
<span class="next">
<a href="crawler-rules.html">Crawl rules »</a>
</span>
</div>
</div>
</body>
</html>
