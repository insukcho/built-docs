<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Crawl rules | Elastic Enterprise Search Documentation [master] | Elastic</title>
<link rel="home" href="index.html" title="Elastic Enterprise Search Documentation [master]"/>
<link rel="up" href="crawler.html" title="Web crawler"/>
<link rel="prev" href="crawler-faq.html" title="Web crawler FAQ"/>
<link rel="next" href="crawler-reference.html" title="Crawler2 reference"/>
<meta name="DC.type" content="Learn/Docs/Enterprise Search/Guide/master"/>
<meta name="DC.subject" content="Enterprise Search"/>
<meta name="DC.identifier" content="master"/>
<meta name="robots" content="noindex,nofollow"/>
</head>
<body><div class="page_header">
You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elastic Enterprise Search Documentation [master]</a></span>
»
<span class="breadcrumb-link"><a href="crawler.html">Web crawler</a></span>
»
<span class="breadcrumb-node">Crawl rules</span>
</div>
<div class="navheader">
<span class="prev">
<a href="crawler-faq.html">« Web crawler FAQ</a>
</span>
<span class="next">
<a href="crawler-reference.html">Crawler2 reference »</a>
</span>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h2 class="title"><a id="crawler-rules"></a>Crawl rules<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-rules.asciidoc">edit</a></h2>
</div></div></div>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="crawler-rules.html#crawler-rules-crawl-rule" title="Crawl rule">Crawl rules overview</a>
</li>
<li class="listitem">
<a class="xref" href="crawler-rules.html#crawler-rules-crawl-rule-rules" title="Crawl rule logic">Crawl rule logic</a>
</li>
<li class="listitem">
<a class="xref" href="crawler-rules.html#crawler-rules-crawl-rule-matching" title="Crawl rule matching">Crawl rule matching</a>
</li>
<li class="listitem">
<a class="xref" href="crawler-rules.html#crawler-rules-crawl-rule-order" title="Crawl rule order">Crawl rule order</a>
</li>
<li class="listitem">
<a class="xref" href="crawler-rules.html#crawler-rules-crawl-rule-restricting-paths" title="Restricting paths using crawl rules">Restricting paths using crawl rules</a>
</li>
</ul>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="crawler-rules-crawl-rule"></a>Crawl rule<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-rules.asciidoc">edit</a></h3>
</div></div></div>
<p>A <em>crawl rule</em> is a crawler instruction to <em>allow</em> or <em>disallow</em> specific paths within a domain.
Each crawl rule belongs to a domain, and each domain has one or more crawl rules.</p>
<p>After modifying your crawl rules, you can re-apply the rules to your existing documents without waiting for a full re-crawl.</p>
<p>During content discovery, the web crawler discovers new URLs and must determine which it is allowed to follow.
Each URL has a <em>domain</em> (e.g. <code class="literal">https://example.com</code>) and a <em>path</em> (e.g. <code class="literal">/category/clothing</code> or <code class="literal">/c/Credit_Center</code>).</p>
<p>The web crawler looks up the crawl rules for the domain, and applies the path to the crawl rules to determine if the path is <em>allowed</em> or <em>disallowed</em>.
The crawler evaluates the crawl rules in order.
The <em>first</em> matching crawl rule determines the policy for the newly discovered URL.</p>
<p>Each crawl rule has a <em>path pattern</em>, a <em>rule</em>, and a <em>policy</em>.
To evaluate each rule, the web crawler compares a newly discovered <em>path</em> to the path pattern, using the logic represented by the rule, resulting in a policy.</p>
<p>The policy for each URL is also affected by directives in robots.txt files.
The web crawler will crawl only those URLs that are allowed by crawl rules <em>and</em> robots.txt directives.</p>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="crawler-rules-crawl-rule-rules"></a>Crawl rule logic<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-rules.asciidoc">edit</a></h3>
</div></div></div>
<p>The logic for each rule is as follows:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
Begins with
</span>
</dt>
<dd>
<p>
The <em>path pattern</em> is a literal string <em>except</em> for the character <code class="literal">*</code>, which is a meta character that will match anything.
</p>
<p>The rule matches when the <em>path pattern</em> matches the <span class="strong strong"><strong>beginning</strong></span> of the <em>path</em> (which always begins with <code class="literal">/</code>).</p>
<p>If using this rule, begin your <em>path pattern</em> with <code class="literal">/</code>.</p>
</dd>
<dt>
<span class="term">
Ends with
</span>
</dt>
<dd>
<p>
The <em>path pattern</em> is a literal string <em>except</em> for the character <code class="literal">*</code>, which is a meta character that will match anything.
</p>
<p>The rule matches when the <em>path pattern</em> matches the <span class="strong strong"><strong>end</strong></span> of the <em>path</em>.</p>
</dd>
<dt>
<span class="term">
Contains
</span>
</dt>
<dd>
<p>
The <em>path pattern</em> is a literal string <em>except</em> for the character <code class="literal">*</code>, which is a meta character that will match anything.
</p>
<p>The rule matches when the <em>path pattern</em> matches anywhere <span class="strong strong"><strong>within</strong></span> the <em>path</em>.</p>
</dd>
<dt>
<span class="term">
Regex
</span>
</dt>
<dd>
<p>
The <em>path pattern</em> is a regular expression compatible with the Ruby language regular expression engine.
In addition to literal characters, the path pattern may include
<a href="https://ruby-doc.org/core-2.5.1/Regexp.html#class-Regexp-label-Metacharacters+and+Escapes" class="ulink" target="_blank" rel="noopener">metacharacters</a>, <a href="https://ruby-doc.org/core-2.5.1/Regexp.html#class-Regexp-label-Character+Classes" class="ulink" target="_blank" rel="noopener">character classes</a>, and <a href="https://ruby-doc.org/core-2.5.1/Regexp.html#class-Regexp-label-Repetition" class="ulink" target="_blank" rel="noopener">repetitions</a>.
You can test Ruby regular expressions using <a href="https://rubular.com" class="ulink" target="_blank" rel="noopener">Rubular</a>.
</p>
<p>The rule matches when the <em>path pattern</em> matches the <span class="strong strong"><strong>beginning</strong></span> of the <em>path</em> (which always begins with <code class="literal">/</code>).</p>
<p>If using this rule, begin your <em>path pattern</em> with <code class="literal">\/</code> or a metacharacter or character class that matches <code class="literal">/</code>.</p>
</dd>
</dl>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h3 class="title"><a id="crawler-rules-crawl-rule-matching"></a>Crawl rule matching<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-rules.asciidoc">edit</a></h3>
</div></div></div>
<p>The following table provides examples of crawl rule matching:</p>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
<col class="col_4"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">URL path</th>
<th align="left" valign="top">Rule</th>
<th align="left" valign="top">Path pattern</th>
<th align="left" valign="top">Match?</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p><code class="literal">/foo/bar</code></p></td>
<td align="left" valign="top"><p><em>Begins with</em></p></td>
<td align="left" valign="top"><p><code class="literal">/foo</code></p></td>
<td align="left" valign="top"><p>YES</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/foo/bar</code></p></td>
<td align="left" valign="top"><p><em>Begins with</em></p></td>
<td align="left" valign="top"><p><code class="literal">/*oo</code></p></td>
<td align="left" valign="top"><p>YES</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/bar/foo</code></p></td>
<td align="left" valign="top"><p><em>Begins with</em></p></td>
<td align="left" valign="top"><p><code class="literal">/foo</code></p></td>
<td align="left" valign="top"><p>NO</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/foo/bar</code></p></td>
<td align="left" valign="top"><p><em>Begins with</em></p></td>
<td align="left" valign="top"><p><code class="literal">foo</code></p></td>
<td align="left" valign="top"><p>NO</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/blog/posts/hello-world</code></p></td>
<td align="left" valign="top"><p><em>Ends</em></p></td>
<td align="left" valign="top"><p><code class="literal">world</code></p></td>
<td align="left" valign="top"><p>YES</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/blog/posts/hello-world</code></p></td>
<td align="left" valign="top"><p><em>Ends</em></p></td>
<td align="left" valign="top"><p><code class="literal">hello-*</code></p></td>
<td align="left" valign="top"><p>YES</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/blog/world-hello</code></p></td>
<td align="left" valign="top"><p><em>Ends</em></p></td>
<td align="left" valign="top"><p><code class="literal">world</code></p></td>
<td align="left" valign="top"><p>NO</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/blog/world-hello</code></p></td>
<td align="left" valign="top"><p><em>Ends</em></p></td>
<td align="left" valign="top"><p><code class="literal">*world</code></p></td>
<td align="left" valign="top"><p>NO</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/fruits/bananas</code></p></td>
<td align="left" valign="top"><p><em>Contains</em></p></td>
<td align="left" valign="top"><p><code class="literal">banana</code></p></td>
<td align="left" valign="top"><p>YES</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/fruits/apples</code></p></td>
<td align="left" valign="top"><p><em>Contains</em></p></td>
<td align="left" valign="top"><p><code class="literal">banana</code></p></td>
<td align="left" valign="top"><p>NO</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/2020</code></p></td>
<td align="left" valign="top"><p><em>Regex</em></p></td>
<td align="left" valign="top"><p><code class="literal">\/[0-9]{3,5}</code></p></td>
<td align="left" valign="top"><p>YES</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/20</code></p></td>
<td align="left" valign="top"><p><em>Regex</em></p></td>
<td align="left" valign="top"><p><code class="literal">\/[0-9]{3,5}</code></p></td>
<td align="left" valign="top"><p>NO</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/2020</code></p></td>
<td align="left" valign="top"><p><em>Regex</em></p></td>
<td align="left" valign="top"><p><code class="literal">[0-9]{3,5}</code></p></td>
<td align="left" valign="top"><p>NO</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="crawler-rules-crawl-rule-order"></a>Crawl rule order<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-rules.asciidoc">edit</a></h4>
</div></div></div>
<p>The <em>first</em> crawl rule to match determines the policy for the URL.
Therefore, the order of the crawl rules is significant.</p>
<p>The following table demonstrates how crawl rule order affects the resulting policy for a path:</p>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">Path</th>
<th align="left" valign="top">Crawl rules</th>
<th align="left" valign="top">Resulting policy</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p><code class="literal">/blog/2021/foo-bar-baz</code></p></td>
<td align="left" valign="top"><p>1. <code class="literal">Disallow</code> if <code class="literal">Begins with</code> <code class="literal">/blog</code></p>
<p>2. <code class="literal">Allow</code> if <code class="literal">Regex</code> <code class="literal">.*</code></p></td>
<td align="left" valign="top"><p>DISALLOW</p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">/blog/2021/foo-bar-baz</code></p></td>
<td align="left" valign="top"><p>1. <code class="literal">Allow</code> if <code class="literal">Regex</code> <code class="literal">.*</code></p>
<p>2. <code class="literal">Disallow</code> if <code class="literal">Begins with</code> <code class="literal">/blog</code></p></td>
<td align="left" valign="top"><p>ALLOW</p></td>
</tr>
</tbody>
</table>
</div>
</div>

<div class="section">
<div class="titlepage"><div><div>
<h4 class="title"><a id="crawler-rules-crawl-rule-restricting-paths"></a>Restricting paths using crawl rules<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/enterprise-search-pubs/edit/main/enterprise-search-docs/crawler/crawler-rules.asciidoc">edit</a></h4>
</div></div></div>
<p>The domain dashboard adds a default crawl rule to each domain: <code class="literal">Allow</code> if <code class="literal">Regex</code> <code class="literal">.*</code>.
You cannot delete or re-order this rule through the dashboard.</p>
<p>This rule is permissive, allowing all paths within the domain.
To restrict paths, use either of the following techniques:</p>
<p>Add rules that disallow specific paths (e.g. disallow the blog):</p>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">Policy</th>
<th align="left" valign="top">Rule</th>
<th align="left" valign="top">Path pattern</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p><code class="literal">Disallow</code></p></td>
<td align="left" valign="top"><p><code class="literal">Begins with</code></p></td>
<td align="left" valign="top"><p><code class="literal">/blog</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">Allow</code></p></td>
<td align="left" valign="top"><p><code class="literal">Regex</code></p></td>
<td align="left" valign="top"><p><code class="literal">.*</code></p></td>
</tr>
</tbody>
</table>
</div>
<p>Or, add rules that allow specific paths and disallow all others (e.g. allow <em>only</em> the blog):</p>
<div class="informaltable">
<table border="1" cellpadding="4px">
<colgroup>
<col class="col_1"/>
<col class="col_2"/>
<col class="col_3"/>
</colgroup>
<thead>
<tr>
<th align="left" valign="top">Policy</th>
<th align="left" valign="top">Rule</th>
<th align="left" valign="top">Path pattern</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" valign="top"><p><code class="literal">Allow</code></p></td>
<td align="left" valign="top"><p><code class="literal">Begins with</code></p></td>
<td align="left" valign="top"><p><code class="literal">/blog</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">Disallow</code></p></td>
<td align="left" valign="top"><p><code class="literal">Regex</code></p></td>
<td align="left" valign="top"><p><code class="literal">.*</code></p></td>
</tr>
<tr>
<td align="left" valign="top"><p><code class="literal">Allow</code></p></td>
<td align="left" valign="top"><p><code class="literal">Regex</code></p></td>
<td align="left" valign="top"><p><code class="literal">.*</code></p></td>
</tr>
</tbody>
</table>
</div>
<p>When you restrict a crawl to specific paths, be sure to add entry points that allow the crawler to discover those paths.
For example, if your crawl rules restrict the crawler to <code class="literal">/blog</code>, add <code class="literal">/blog</code> as an entry point.</p>
<p>If you leave only the default entry point of <code class="literal">/</code>, the crawl will end immediately, since <code class="literal">/</code> is disallowed.</p>
</div>

</div>

</div>
<div class="navfooter">
<span class="prev">
<a href="crawler-faq.html">« Web crawler FAQ</a>
</span>
<span class="next">
<a href="crawler-reference.html">Crawler2 reference »</a>
</span>
</div>
</div>
</body>
</html>
