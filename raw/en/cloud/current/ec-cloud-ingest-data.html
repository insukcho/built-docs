<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<title>Indexing data into Elasticsearch | Elasticsearch Service Documentation | Elastic</title>
<link rel="home" href="index.html" title="Elasticsearch Service Documentation"/>
<link rel="up" href="index.html" title="Elasticsearch Service Documentation"/>
<link rel="prev" href="ec-billing-azure.html" title="Azure Marketplace (deprecated)"/>
<link rel="next" href="ec-best-practices-data.html" title="Best practices for managing your data"/>
<meta name="DC.type" content="Learn/Docs/Cloud/Reference"/>
<meta name="DC.subject" content="Elastic Cloud"/>
<meta name="DC.identifier" content="latest"/>
</head>
<body>
<div id="content">
<div class="breadcrumbs">
<span class="breadcrumb-link"><a href="index.html">Elasticsearch Service Documentation</a></span>
»
<span class="breadcrumb-node">Indexing data into Elasticsearch</span>
</div>
<div class="navheader">
<span class="prev">
<a href="ec-billing-azure.html">« Azure Marketplace (deprecated)</a>
</span>
<span class="next">
<a href="ec-best-practices-data.html">Best practices for managing your data »</a>
</span>
</div>
<div class="part">
<div class="titlepage"><div><div>
<h1 class="title"><a id="ec-cloud-ingest-data"></a>Indexing data into Elasticsearch<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h1>
</div></div></div>
<div class="openblock partintro">
<div class="content">
<p>By now you&#8217;ve probably spun up a deployment and might be wondering what&#8217;s next. Congratulations on completing that first big step! Now let&#8217;s help you <em>do</em> something with it. You likely have data that you want to add, known as <em>ingesting</em> or <em>indexing</em>, to Elasticsearch, so let&#8217;s explore some options.</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="ec-cloud-ingest-data.html#ec-migrating-data" title="Migrating data">Migrating data</a>
</li>
<li class="listitem">
<a class="xref" href="ec-cloud-ingest-data.html#ec-ingest-methods" title="Ingestion methods">Ingestion methods</a>
</li>
<li class="listitem">
<a class="xref" href="ec-cloud-ingest-data.html#ec-ingest-sample-data" title="Try out sample data">Try out sample data</a>
</li>
<li class="listitem">
<a class="xref" href="ec-cloud-ingest-data.html#ec-ingest-solutions" title="Ingest data with Elastic solutions">Ingest data with Elastic solutions</a>
</li>
<li class="listitem">
<a class="xref" href="ec-cloud-ingest-data.html#ec-ingest-guides" title="Ingest from custom sources">Ingest from custom sources</a>
</li>
</ul>
</div>
<p>Check also the <a class="xref" href="ec-best-practices-data.html" title="Best practices for managing your data">best practices for managing your data</a>.</p>
<h2><a id="ec-migrating-data"></a>Migrating data<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h2>
<p>If you want to move your existing Elasticsearch data into your new infrastructure, check out the <a class="xref" href="ec-migrate-data.html" title="Migrate your Elasticsearch data">migration options</a>. You&#8217;ll find instructions to guide you through:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
Migrating data from its original source
</li>
<li class="listitem">
Reindexing data from a remote Elasticsearch cluster
</li>
<li class="listitem">
Restoring data from a snapshot
</li>
<li class="listitem">
Migrating internal Elasticsearch indices
</li>
</ul>
</div>
<h2><a id="ec-ingest-methods"></a>Ingestion methods<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h2>
<p>When it comes to delivering your data into the Elastic Stack, a variety of options are available. All of the documentation and tutorials listed here rely on one of four ingestion methods: Elastic Agent, Beats, Logstash, or a direct connection from a client application. You can use these options individually or in combination.</p>
<p>Trying to choose between Beats or Elastic Agent? Check out our comparison of supported inputs, outputs, and configurations: <a href="/guide/en/fleet/8.1/beats-agent-comparison.html" class="ulink" target="_top">Beats and Elastic Agent capabilities</a>.</p>
<h3><a id="ec-data-ingest-agent"></a>Elastic Agent and Fleet<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h3>
<p>Elastic Agent offers a single, unified way to enable shipping monitoring data from multiple hosts or containers into the Elastic Stack. Elastic Agent serves as a convenient front end that uses Beats shippers or Elastic Endpoint under the covers. Check the <a href="/guide/en/fleet/8.1/elastic-agent-installation.html" class="ulink" target="_top">Elastic Agents product documentation</a> to learn more.</p>
<p>Fleet provides a web-based UI in Kibana to add and manage integrations for popular services and platforms, as well as manage a fleet of Elastic Agents. To learn more about how these work, check the <a href="/guide/en/fleet/8.1/fleet-overview.html" class="ulink" target="_top">Fleet and Elastic Agent overview</a>.</p>
<h3><a id="ec-data-ingest-beats"></a>Beats<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h3>
<p>These lightweight shippers get installed as agents on the endpoint. The data that they collect gets <em>pushed</em> back to the Elasticsearch cluster. Each Beat is created with a specific purpose, making it possible to target and aggregate common data from a multitude of endpoints. Some Beats, like Filebeat, have modules that specialize them even further. Configure the Beat to use the <a class="xref" href="ec-cloud-id.html" title="Configure Beats and Logstash with Cloud ID">Cloud ID</a> to simplify sending data back to your deployment. TLS, basic authentication, and API key authentication are available to ensure that your data is shipped securely.</p>
<p>Here&#8217;s a short and incomplete list of the types of data that Beats can handle: log files, metrics, audit data, network traffic, uptime monitoring, and more. Learn about the possibilities from the <a href="/guide/en/beats/libbeat/8.1/getting-started.html" class="ulink" target="_top">Beats documentation</a>.</p>
<h3><a id="ec-data-ingest-logstash"></a>Logstash<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h3>
<p>Logstash is an open source data collection engine with real-time pipelining capabilities. It can accept data that is pushed to it as well as <em>pull</em> data from external sources. Logstash has the added benefit of being able to persist information in queues if the cluster temporarily cannot accept data, smoothing out ingestion spikes. However, Logstash is not available as part of the Elasticsearch Service deployment and requires separate installation and maintenance. Use the <a class="xref" href="ec-cloud-id.html" title="Configure Beats and Logstash with Cloud ID">Cloud ID</a> to configure Logstash to work with a deployment. And, as with Beats, you have the option of using basic authentication or an API key for secure data transmission.</p>
<p>Learn more about the possible inputs, filters, and outputs from the <a href="/guide/en/logstash/8.1/introduction.html" class="ulink" target="_top">Logstash documentation</a>.</p>
<h3><a id="ec-data-ingest-client"></a>Language clients<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h3>
<p>Elastic provides libraries for several programming languages that allow you to connect your code directly to your Elasticsearch Service deployment. A unique Cloud ID. TLS, basic authentication, and API key authentication methods are available to ensure that your data is shipped securely into Elasticsearch.</p>
<p>This approach is described in detail in the two guides:</p>
<div class="ulist itemizedlist">
<ul class="itemizedlist">
<li class="listitem">
<a class="xref" href="ec-getting-started-node-js.html" title="Ingest data with Node.js on Elasticsearch Service">Ingest data with Node.js on Elasticsearch Service</a>
</li>
<li class="listitem">
<a class="xref" href="ec-getting-started-python.html" title="Ingest data with Python on Elasticsearch Service">Ingest data with Python on Elasticsearch Service</a>
</li>
</ul>
</div>
<p>The details for each programming language library provided are in the <a href="/guide/en/elasticsearch/client/index.html" class="ulink" target="_top">Elasticsearch Client documentation</a>.</p>
<h2><a id="ec-ingest-sample-data"></a>Try out sample data<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h2>
<p>There are number of ways for you to get a sample data set ingested into Elasticsearch. This gives you a convenient way to test drive the broad set of Kibana tools and visualizations before ingesting your own data. Several data packages are available with a single-step installation, as well as a <code class="literal">makelogs</code> script and a simple CSV upload method for more ingest options.</p>
<p>To learn more, check <a href="/guide/en/kibana/8.1/sample-data.html" class="ulink" target="_top">Installing sample data</a>.</p>
<h2><a id="ec-ingest-solutions"></a>Ingest data with Elastic solutions<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h2>
<p>You can choose from one of the following guides to find the most suitable data ingestion steps and examples for your needs.</p>
<h3><a id="ec_enterprise_search"></a>Enterprise Search<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h3>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<a href="/guide/en/app-search/8.1/getting-started.html" class="ulink" target="_top">Getting started with App Search</a>
</span>
</dt>
<dd>
The App Search getting started documentation and video can help you to index an initial set of documents to create a custom search experience in your applications.
</dd>
<dt>
<span class="term">
<a href="/guide/en/workplace-search/8.1/workplace-search-content-sources.html" class="ulink" target="_top">Workplace Search Content Sources Overview</a>
</span>
</dt>
<dd>
Learn how to integrate Workplace Search with a variety of third-party content sources such as GitHub, Google Drive, or Dropbox. You can also build your own connectors using custom API sources, allowing you to search unique content repositories and ingest that data into Workplace Search.
</dd>
<dt>
<span class="term">
<a href="/guide/en/app-search/8.1/web-crawler.html" class="ulink" target="_top">Enterprise Search web crawler</a>
</span>
</dt>
<dd>
The Elastic Enterprise Search web crawler, currently a beta feature, discovers, extracts, and indexes your web content into your App Search engines.
</dd>
</dl>
</div>
<h3><a id="ec_observability"></a>Observability<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h3>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<a href="/guide/en/observability/8.1/add-observability-data.html" class="ulink" target="_top">Send data to Elasticsearch</a>
</span>
</dt>
<dd>
These steps get you started with the ingestion aspects of Elastic Observability, detailing how to configure Elasticsearch to store and search your data, and Kibana to visualize and manage it. You can also set up APM Server as part of an Elasticsearch Service deployment and then configure APM agents to send data into the deployment.
</dd>
<dt>
<span class="term">
<a href="/guide/en/observability/8.1/observability-tutorials.html" class="ulink" target="_top">Tutorials</a>
</span>
</dt>
<dd>
Try out these tutorials to guide you through specific observability scenarios, including monitoring data from AWS, GCP, or Azure, in a Java application, or from Kubernetes.
</dd>
</dl>
</div>
<h3><a id="ec_security"></a>Security<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h3>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<a href="/guide/en/security/8.1/ingest-data.html" class="ulink" target="_top">Ingest data to Elastic Security</a>
</span>
</dt>
<dd>
This guide presents options for ingesting data into Elastic Security, including using the Elastic Agent with Elastic Endpoint Integration, using Beats shippers installed on the systems that you want to monitor, using Elastic Agent with Splunk, and using third party collectors shipping ECS-compliant data.
</dd>
<dt>
<span class="term">
<a href="/guide/en/siem/guide/current/install-siem.html#siem-ingest" class="ulink" target="_top">Ingest data into SIEM</a>
</span>
</dt>
<dd>
Learn about how to ingest data into the Elastic SIEM app (now part of the Elastic Security solution), including using Beats shippers installed on the systems that you want to monitor, using Elastic Endpoint Security to ship data directly to Elasticsearch, and using third party collectors shipping ECS-compliant data.
</dd>
</dl>
</div>
<h2><a id="ec-ingest-guides"></a>Ingest from custom sources<a class="edit_me edit_me_private" rel="nofollow" title="Editing on GitHub is available to Elastic" href="https://github.com/elastic/cloud/edit/ms-70/docs/shared/ec-ce-cloud-ingest-data.asciidoc">edit</a></h2>
<p>These guides describe the process of securely ingesting your custom data into an Elasticsearch Service deployment, whether it be client application data, ECS (Elastic Common Schema)-formatted log data, server monitoring metrics, or relational database records that you want to synchronize with Elasticsearch.</p>
<p>In addition, have a look at our large collection of prebuilt <a href="/integrations" class="ulink" target="_top">Elastic integrations</a> that enable you connect and easily stream in logs, metrics, traces, content, and other data types from popular sources.</p>
<p>Learn how to:</p>
<div class="variablelist">
<dl class="variablelist">
<dt>
<span class="term">
<a class="xref" href="ec-getting-started-node-js.html" title="Ingest data with Node.js on Elasticsearch Service">Ingest data with Node.js on Elasticsearch Service</a>
</span>
</dt>
<dd>
Get Node.js application data securely into Elasticsearch Service, where it can then be searched and modified.
</dd>
<dt>
<span class="term">
<a class="xref" href="ec-getting-started-python.html" title="Ingest data with Python on Elasticsearch Service">Ingest data with Python on Elasticsearch Service</a>
</span>
</dt>
<dd>
Get Python application data securely into Elasticsearch Service, where it can then be searched and modified.
</dd>
<dt>
<span class="term">
<a class="xref" href="ec-getting-started-search-use-cases-beats-logstash.html" title="Ingest data from Beats to Elasticsearch Service with Logstash as a proxy">Ingest data from Beats to Elasticsearch Service with Logstash as a proxy</a>
</span>
</dt>
<dd>
Get server metrics or other types of data from Filebeat and Metricbeat into Logstash as an intermediary, and then send that data to Elasticsearch Service. Using Logstash as a proxy limits your Elastic Stack traffic through a single, external-facing firewall exception or rule.
</dd>
<dt>
<span class="term">
<a class="xref" href="ec-getting-started-search-use-cases-db-logstash.html" title="Ingest data from a relational database into Elasticsearch Service">Ingest data from a relational database into Elasticsearch Service</a>
</span>
</dt>
<dd>
Get data from a relational database into Elasticsearch Service using the Logstash JDBC input plugin. Logstash can be used as an efficient way to copy records and to receive updates from a relational database as changes happen, and then send the new data to a deployment.
</dd>
<dt>
<span class="term">
<a class="xref" href="ec-getting-started-search-use-cases-python-logs.html" title="Ingest logs from a Python application using Filebeat">Ingest logs from a Python application using Filebeat</a>
</span>
</dt>
<dd>
Get logs from a Python application and deliver them securely into an Elasticsearch Service deployment. You&#8217;ll set up Filebeat to monitor an ECS-formatted log file, and then view real-time visualizations of the log events in Kibana as they occur.
</dd>
<dt>
<span class="term">
<a class="xref" href="ec-getting-started-search-use-cases-node-logs.html" title="Ingest logs from a Node.js web application using Filebeat">Ingest logs from a Node.js web application using Filebeat</a>
</span>
</dt>
<dd>
Get HTTP request logs from a Node.js web application and deliver them securely into an Elasticsearch Service deployment. You&#8217;ll set up Filebeat to monitor an ECS-formatted log file and then view real-time visualizations of the log events as HTTP requests occur on your Node.js web server.
</dd>
</dl>
</div>
<div class="tip admon">
<div class="icon"></div>
<div class="admon_content">
<p>Whenever you add data into Elasticsearch indices, that data can be pre-processed using an Elasticsearch ingest pipeline. An ingest pipeline is an ideal way to optimize how your data is indexed. It simplifies tasks such as extracting error codes from a log file, or mapping geographic locations to IP addresses. To learn about ingest preprocessors and pipelines check the <a href="/guide/en/elasticsearch/reference/8.1/ingest.html" class="ulink" target="_top">Elasticsearch ingest documentation</a>.</p>
</div>
</div>
</div>
</div>




</div>
<div class="navfooter">
<span class="prev">
<a href="ec-billing-azure.html">« Azure Marketplace (deprecated)</a>
</span>
<span class="next">
<a href="ec-best-practices-data.html">Best practices for managing your data »</a>
</span>
</div>
</div>
</body>
</html>
